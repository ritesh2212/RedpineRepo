{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small JIT Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def foo(a, b):\n",
    "    c = 2 * b\n",
    "    a += 1\n",
    "    if a.max() > 4:\n",
    "        r = a[0]\n",
    "    else:\n",
    "        r = b[0]\n",
    "    return c, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(2, 3)\n",
    "b = torch.ones(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%x : Float(3),\n",
      "      %y : Float(3)):\n",
      "  %2 : Long() = prim::Constant[value={2}]() # <ipython-input-5-3c10302655ac>:4:0\n",
      "  %3 : Float(3) = aten::mul(%x, %2) # <ipython-input-5-3c10302655ac>:4:0\n",
      "  %4 : int = prim::Constant[value=1]() # <ipython-input-5-3c10302655ac>:4:0\n",
      "  %5 : Float(3) = aten::add(%3, %y, %4) # <ipython-input-5-3c10302655ac>:4:0\n",
      "  return (%5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def foo(x, y):\n",
    "    return 2 * x + y\n",
    "traced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3)))\n",
    "\n",
    "@torch.jit.script\n",
    "def bar(x):\n",
    "    return traced_foo(x, x)\n",
    "\n",
    "print(traced_foo.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the network (LeNet-5)  \n",
    "class LeNet5(torch.nn.Module):\n",
    "     \n",
    "    def __init__(self):   \n",
    "        super(LeNet5, self).__init__()\n",
    "        # Convolution (In LeNet-5, 32x32 images are given as input. Hence padding of 2 is done below)\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        # Max-pooling\n",
    "        self.max_pool_1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Convolution\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)\n",
    "        # Max-pooling\n",
    "        self.max_pool_2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Fully connected layer\n",
    "        self.fc1 = torch.nn.Linear(16*5*5, 120)   # convert matrix with 16*5*5 (= 400) features to a matrix of 120 features (columns)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)       # convert matrix with 120 features to a matrix of 84 features (columns)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)        # convert matrix with 84 features to a matrix of 10 features (columns)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # convolve, then perform ReLU non-linearity\n",
    "        x = torch.nn.functional.relu(self.conv1(x))  \n",
    "        # max-pooling with 2x2 grid\n",
    "        x = self.max_pool_1(x)\n",
    "        # convolve, then perform ReLU non-linearity\n",
    "        x = torch.nn.functional.relu(self.conv2(x))\n",
    "        # max-pooling with 2x2 grid\n",
    "        x = self.max_pool_2(x)\n",
    "        # first flatten 'max_pool_2_out' to contain 16*5*5 columns\n",
    "        # read through https://stackoverflow.com/a/42482819/7551231\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        # FC-1, then perform ReLU non-linearity\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        # FC-2, then perform ReLU non-linearity\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        # FC-3\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unoptimized JIT TRACE of LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.torch.nn.modules.module.___torch_mangle_8.Module,\n",
       "      %input.1 : Float(1, 1, 28, 28)):\n",
       "  %134 : __torch__.torch.nn.modules.module.___torch_mangle_7.Module = prim::GetAttr[name=\"fc3\"](%self.1)\n",
       "  %131 : __torch__.torch.nn.modules.module.___torch_mangle_6.Module = prim::GetAttr[name=\"fc2\"](%self.1)\n",
       "  %128 : __torch__.torch.nn.modules.module.___torch_mangle_5.Module = prim::GetAttr[name=\"fc1\"](%self.1)\n",
       "  %125 : __torch__.torch.nn.modules.module.___torch_mangle_4.Module = prim::GetAttr[name=\"max_pool_2\"](%self.1)\n",
       "  %124 : __torch__.torch.nn.modules.module.___torch_mangle_3.Module = prim::GetAttr[name=\"conv2\"](%self.1)\n",
       "  %121 : __torch__.torch.nn.modules.module.___torch_mangle_2.Module = prim::GetAttr[name=\"max_pool_1\"](%self.1)\n",
       "  %120 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"conv1\"](%self.1)\n",
       "  %142 : Tensor = prim::CallMethod[name=\"forward\"](%120, %input.1)\n",
       "  %input.3 : Float(1, 6, 28, 28) = aten::relu(%142) # /home/ritesh/miniconda3/envs/py3/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
       "  %143 : Tensor = prim::CallMethod[name=\"forward\"](%121, %input.3)\n",
       "  %144 : Tensor = prim::CallMethod[name=\"forward\"](%124, %143)\n",
       "  %input.6 : Float(1, 16, 10, 10) = aten::relu(%144) # /home/ritesh/miniconda3/envs/py3/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
       "  %145 : Tensor = prim::CallMethod[name=\"forward\"](%125, %input.6)\n",
       "  %93 : int = prim::Constant[value=-1]() # <ipython-input-6-5b68f572a232>:30:0\n",
       "  %94 : int = prim::Constant[value=400]() # <ipython-input-6-5b68f572a232>:30:0\n",
       "  %95 : int[] = prim::ListConstruct(%93, %94)\n",
       "  %input.7 : Float(1, 400) = aten::view(%145, %95) # <ipython-input-6-5b68f572a232>:30:0\n",
       "  %146 : Tensor = prim::CallMethod[name=\"forward\"](%128, %input.7)\n",
       "  %input.9 : Float(1, 120) = aten::relu(%146) # /home/ritesh/miniconda3/envs/py3/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
       "  %147 : Tensor = prim::CallMethod[name=\"forward\"](%131, %input.9)\n",
       "  %input : Float(1, 84) = aten::relu(%147) # /home/ritesh/miniconda3/envs/py3/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
       "  %148 : Tensor = prim::CallMethod[name=\"forward\"](%134, %input)\n",
       "  return (%148)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripted_module = torch.jit.trace(LeNet5(),torch.rand(1,1,28,28))\n",
    "scripted_module.graph # unpoptimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized JIT TRACE of LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.torch.nn.modules.module.___torch_mangle_24.Module,\n",
       "      %input.1 : Float(1, 1, 28, 28)):\n",
       "  %134 : __torch__.torch.nn.modules.module.___torch_mangle_23.Module = prim::GetAttr[name=\"fc3\"](%self.1)\n",
       "  %131 : __torch__.torch.nn.modules.module.___torch_mangle_22.Module = prim::GetAttr[name=\"fc2\"](%self.1)\n",
       "  %128 : __torch__.torch.nn.modules.module.___torch_mangle_21.Module = prim::GetAttr[name=\"fc1\"](%self.1)\n",
       "  %125 : __torch__.torch.nn.modules.module.___torch_mangle_20.Module = prim::GetAttr[name=\"max_pool_2\"](%self.1)\n",
       "  %124 : __torch__.torch.nn.modules.module.___torch_mangle_19.Module = prim::GetAttr[name=\"conv2\"](%self.1)\n",
       "  %121 : __torch__.torch.nn.modules.module.___torch_mangle_18.Module = prim::GetAttr[name=\"max_pool_1\"](%self.1)\n",
       "  %120 : __torch__.torch.nn.modules.module.___torch_mangle_17.Module = prim::GetAttr[name=\"conv1\"](%self.1)\n",
       "  %142 : Tensor = prim::CallMethod[name=\"forward\"](%120, %input.1)\n",
       "  %input.3 : Float(1, 6, 28, 28) = aten::relu(%142) # /home/ritesh/miniconda3/envs/py3/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
       "  %143 : Tensor = prim::CallMethod[name=\"forward\"](%121, %input.3)\n",
       "  %144 : Tensor = prim::CallMethod[name=\"forward\"](%124, %143)\n",
       "  %input.6 : Float(1, 16, 10, 10) = aten::relu(%144) # /home/ritesh/miniconda3/envs/py3/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
       "  %145 : Tensor = prim::CallMethod[name=\"forward\"](%125, %input.6)\n",
       "  %93 : int = prim::Constant[value=-1]() # <ipython-input-6-5b68f572a232>:30:0\n",
       "  %94 : int = prim::Constant[value=400]() # <ipython-input-6-5b68f572a232>:30:0\n",
       "  %95 : int[] = prim::ListConstruct(%93, %94)\n",
       "  %input.7 : Float(1, 400) = aten::view(%145, %95) # <ipython-input-6-5b68f572a232>:30:0\n",
       "  %146 : Tensor = prim::CallMethod[name=\"forward\"](%128, %input.7)\n",
       "  %input.9 : Float(1, 120) = aten::relu(%146) # /home/ritesh/miniconda3/envs/py3/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
       "  %147 : Tensor = prim::CallMethod[name=\"forward\"](%131, %input.9)\n",
       "  %input : Float(1, 84) = aten::relu(%147) # /home/ritesh/miniconda3/envs/py3/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
       "  %148 : Tensor = prim::CallMethod[name=\"forward\"](%134, %input)\n",
       "  return (%148)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.jit.optimized_execution(3):\n",
    "    scripted_module = torch.jit.trace(LeNet5(),torch.rand(1,1,28,28))\n",
    "scripted_module.graph  # for opt 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpotimized JIT Script of LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritesh/miniconda3/envs/py3/lib/python3.7/site-packages/torch/jit/__init__.py:1252: UserWarning: `optimize` is deprecated and has no effect. Use `with torch.jit.optimized_execution() instead\n",
      "  warnings.warn(\"`optimize` is deprecated and has no effect. Use `with torch.jit.optimized_execution() instead\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "graph(%self : __torch__.LeNet5,\n",
       "      %x.1 : Tensor):\n",
       "  %40 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %34 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %23 : int = prim::Constant[value=-1]() # <ipython-input-6-5b68f572a232>:30:19\n",
       "  %15 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %6 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %5 : bool = prim::Constant[value=0]()\n",
       "  %24 : int = prim::Constant[value=16]() # <ipython-input-6-5b68f572a232>:30:23\n",
       "  %25 : int = prim::Constant[value=5]() # <ipython-input-6-5b68f572a232>:30:26\n",
       "  %2 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%self)\n",
       "  %4 : Tensor = prim::CallMethod[name=\"forward\"](%2, %x.1) # <ipython-input-6-5b68f572a232>:21:37\n",
       "  %x.3 : Tensor = prim::CallFunction(%6, %4, %5) # <ipython-input-6-5b68f572a232>:21:12\n",
       "  %8 : __torch__.torch.nn.modules.pooling.MaxPool2d = prim::GetAttr[name=\"max_pool_1\"](%self)\n",
       "  %x.5 : Tensor = prim::CallMethod[name=\"forward\"](%8, %x.3) # <ipython-input-6-5b68f572a232>:23:12\n",
       "  %11 : __torch__.torch.nn.modules.conv.___torch_mangle_33.Conv2d = prim::GetAttr[name=\"conv2\"](%self)\n",
       "  %13 : Tensor = prim::CallMethod[name=\"forward\"](%11, %x.5) # <ipython-input-6-5b68f572a232>:25:37\n",
       "  %x.7 : Tensor = prim::CallFunction(%15, %13, %5) # <ipython-input-6-5b68f572a232>:25:12\n",
       "  %17 : __torch__.torch.nn.modules.pooling.MaxPool2d = prim::GetAttr[name=\"max_pool_2\"](%self)\n",
       "  %x.9 : Tensor = prim::CallMethod[name=\"forward\"](%17, %x.7) # <ipython-input-6-5b68f572a232>:27:12\n",
       "  %26 : int = aten::mul(%24, %25) # <ipython-input-6-5b68f572a232>:30:23\n",
       "  %27 : int = aten::mul(%26, %25) # <ipython-input-6-5b68f572a232>:30:23\n",
       "  %28 : int[] = prim::ListConstruct(%23, %27)\n",
       "  %x.11 : Tensor = aten::view(%x.9, %28) # <ipython-input-6-5b68f572a232>:30:12\n",
       "  %30 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc1\"](%self)\n",
       "  %32 : Tensor = prim::CallMethod[name=\"forward\"](%30, %x.11) # <ipython-input-6-5b68f572a232>:32:37\n",
       "  %x.13 : Tensor = prim::CallFunction(%34, %32, %5) # <ipython-input-6-5b68f572a232>:32:12\n",
       "  %36 : __torch__.torch.nn.modules.linear.___torch_mangle_34.Linear = prim::GetAttr[name=\"fc2\"](%self)\n",
       "  %38 : Tensor = prim::CallMethod[name=\"forward\"](%36, %x.13) # <ipython-input-6-5b68f572a232>:34:37\n",
       "  %x.15 : Tensor = prim::CallFunction(%40, %38, %5) # <ipython-input-6-5b68f572a232>:34:12\n",
       "  %42 : __torch__.torch.nn.modules.linear.___torch_mangle_35.Linear = prim::GetAttr[name=\"fc3\"](%self)\n",
       "  %x.17 : Tensor = prim::CallMethod[name=\"forward\"](%42, %x.15) # <ipython-input-6-5b68f572a232>:36:12\n",
       "  return (%x.17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripted_module = torch.jit.script(LeNet5(),torch.rand(1,1,28,28))\n",
    "scripted_module.graph # unpoptimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized JIT Script of LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : __torch__.LeNet5,\n",
       "      %x.1 : Tensor):\n",
       "  %40 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %34 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %23 : int = prim::Constant[value=-1]() # <ipython-input-6-5b68f572a232>:30:19\n",
       "  %15 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %6 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %5 : bool = prim::Constant[value=0]()\n",
       "  %24 : int = prim::Constant[value=16]() # <ipython-input-6-5b68f572a232>:30:23\n",
       "  %25 : int = prim::Constant[value=5]() # <ipython-input-6-5b68f572a232>:30:26\n",
       "  %2 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%self)\n",
       "  %4 : Tensor = prim::CallMethod[name=\"forward\"](%2, %x.1) # <ipython-input-6-5b68f572a232>:21:37\n",
       "  %x.3 : Tensor = prim::CallFunction(%6, %4, %5) # <ipython-input-6-5b68f572a232>:21:12\n",
       "  %8 : __torch__.torch.nn.modules.pooling.MaxPool2d = prim::GetAttr[name=\"max_pool_1\"](%self)\n",
       "  %x.5 : Tensor = prim::CallMethod[name=\"forward\"](%8, %x.3) # <ipython-input-6-5b68f572a232>:23:12\n",
       "  %11 : __torch__.torch.nn.modules.conv.___torch_mangle_33.Conv2d = prim::GetAttr[name=\"conv2\"](%self)\n",
       "  %13 : Tensor = prim::CallMethod[name=\"forward\"](%11, %x.5) # <ipython-input-6-5b68f572a232>:25:37\n",
       "  %x.7 : Tensor = prim::CallFunction(%15, %13, %5) # <ipython-input-6-5b68f572a232>:25:12\n",
       "  %17 : __torch__.torch.nn.modules.pooling.MaxPool2d = prim::GetAttr[name=\"max_pool_2\"](%self)\n",
       "  %x.9 : Tensor = prim::CallMethod[name=\"forward\"](%17, %x.7) # <ipython-input-6-5b68f572a232>:27:12\n",
       "  %26 : int = aten::mul(%24, %25) # <ipython-input-6-5b68f572a232>:30:23\n",
       "  %27 : int = aten::mul(%26, %25) # <ipython-input-6-5b68f572a232>:30:23\n",
       "  %28 : int[] = prim::ListConstruct(%23, %27)\n",
       "  %x.11 : Tensor = aten::view(%x.9, %28) # <ipython-input-6-5b68f572a232>:30:12\n",
       "  %30 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc1\"](%self)\n",
       "  %32 : Tensor = prim::CallMethod[name=\"forward\"](%30, %x.11) # <ipython-input-6-5b68f572a232>:32:37\n",
       "  %x.13 : Tensor = prim::CallFunction(%34, %32, %5) # <ipython-input-6-5b68f572a232>:32:12\n",
       "  %36 : __torch__.torch.nn.modules.linear.___torch_mangle_34.Linear = prim::GetAttr[name=\"fc2\"](%self)\n",
       "  %38 : Tensor = prim::CallMethod[name=\"forward\"](%36, %x.13) # <ipython-input-6-5b68f572a232>:34:37\n",
       "  %x.15 : Tensor = prim::CallFunction(%40, %38, %5) # <ipython-input-6-5b68f572a232>:34:12\n",
       "  %42 : __torch__.torch.nn.modules.linear.___torch_mangle_35.Linear = prim::GetAttr[name=\"fc3\"](%self)\n",
       "  %x.17 : Tensor = prim::CallMethod[name=\"forward\"](%42, %x.15) # <ipython-input-6-5b68f572a232>:36:12\n",
       "  return (%x.17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.jit.optimized_execution(3):\n",
    "    scripted_module = torch.jit.script(LeNet5(),torch.rand(1,1,28,28))\n",
    "scripted_module.graph  # fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 1, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "n = Net()\n",
    "example_weight = torch.rand(1, 1, 3, 3)\n",
    "example_forward_input = torch.rand(1, 1, 3, 3)\n",
    "\n",
    "# Trace a specific method and construct `ScriptModule` with\n",
    "# a single `forward` method\n",
    "with torch.jit.optimized_execution(3):\n",
    "    module = torch.jit.trace(n.forward, example_forward_input)\n",
    "\n",
    "# Trace a module (implicitly traces `forward`) and construct a\n",
    "# `ScriptModule` with a single `forward` method\n",
    "# module = torch.jit.trace(n, example_forward_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.torch.nn.modules.module.___torch_mangle_48.Module,\n",
       "      %input : Float(1, 1, 3, 3)):\n",
       "  %28 : __torch__.torch.nn.modules.module.___torch_mangle_47.Module = prim::GetAttr[name=\"conv\"](%self.1)\n",
       "  %30 : Tensor = prim::CallMethod[name=\"forward\"](%28, %input)\n",
       "  return (%30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
