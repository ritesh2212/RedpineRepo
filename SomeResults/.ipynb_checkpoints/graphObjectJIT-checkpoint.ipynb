{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def foo(a, b):\n",
    "    c = 2 * b\n",
    "    a += 1\n",
    "    if a.max() > 4:\n",
    "        r = a[0]\n",
    "    else:\n",
    "        r = b[0]\n",
    "    return c, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(2, 3)\n",
    "b = torch.ones(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%x : Float(3),\n",
      "      %y : Float(3)):\n",
      "  %2 : Long() = prim::Constant[value={2}]() # <ipython-input-7-3c10302655ac>:4:0\n",
      "  %3 : Float(3) = aten::mul(%x, %2) # <ipython-input-7-3c10302655ac>:4:0\n",
      "  %4 : int = prim::Constant[value=1]() # <ipython-input-7-3c10302655ac>:4:0\n",
      "  %5 : Float(3) = aten::add(%3, %y, %4) # <ipython-input-7-3c10302655ac>:4:0\n",
      "  return (%5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def foo(x, y):\n",
    "    return 2 * x + y\n",
    "traced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3)))\n",
    "\n",
    "@torch.jit.script\n",
    "def bar(x):\n",
    "    return traced_foo(x, x)\n",
    "\n",
    "print(traced_foo.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def LSTMCellS(x, hx, cx, w_ih, w_hh, b_ih, b_hh):\n",
    "    gates = x.mm(w_ih.t()) + hx.mm(w_hh.t()) + b_ih + b_hh\n",
    "    ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "    ingate = torch.sigmoid(ingate)\n",
    "    forgetgate = torch.sigmoid(forgetgate)\n",
    "    cellgate = torch.tanh(cellgate)\n",
    "    outgate = torch.sigmoid(outgate)\n",
    "    cy = (forgetgate * cx) + (ingate * cellgate)\n",
    "    hy = outgate * torch.tanh(cy)\n",
    "    return hy, cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_foo = torch.jit.trace(LSTMCellS, (torch.rand(3), torch.rand(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        # torch.jit.trace produces a ScriptModule's conv1 and conv2\n",
    "        self.conv1 = torch.jit.trace(nn.Conv2d(1, 20, 5), torch.rand(1, 1, 16, 16))\n",
    "        self.conv2 = torch.jit.trace(nn.Conv2d(20, 20, 5), torch.rand(1, 20, 16, 16))\n",
    "\n",
    "    def forward(self, input):\n",
    "      input = F.relu(self.conv1(input))\n",
    "      input = F.relu(self.conv2(input))\n",
    "      return input\n",
    "\n",
    "scripted_module = torch.jit.script(MyModule())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : __torch__.MyModule,\n",
       "      %input.1 : Tensor):\n",
       "  %12 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %6 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %5 : bool = prim::Constant[value=0]()\n",
       "  %2 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"conv1\"](%self)\n",
       "  %4 : Tensor = prim::CallMethod[name=\"forward\"](%2, %input.1) # <ipython-input-9-0766fbb23a95>:13:21\n",
       "  %input.3 : Tensor = prim::CallFunction(%6, %4, %5) # <ipython-input-9-0766fbb23a95>:13:14\n",
       "  %8 : __torch__.torch.nn.modules.module.___torch_mangle_3.Module = prim::GetAttr[name=\"conv2\"](%self)\n",
       "  %10 : Tensor = prim::CallMethod[name=\"forward\"](%8, %input.3) # <ipython-input-9-0766fbb23a95>:14:21\n",
       "  %input.5 : Tensor = prim::CallFunction(%12, %10, %5) # <ipython-input-9-0766fbb23a95>:14:14\n",
       "  return (%input.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripted_module.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the network (LeNet-5)  \n",
    "class LeNet5(torch.nn.Module):\n",
    "     \n",
    "    def __init__(self):   \n",
    "        super(LeNet5, self).__init__()\n",
    "        # Convolution (In LeNet-5, 32x32 images are given as input. Hence padding of 2 is done below)\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        # Max-pooling\n",
    "        self.max_pool_1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Convolution\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)\n",
    "        # Max-pooling\n",
    "        self.max_pool_2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Fully connected layer\n",
    "        self.fc1 = torch.nn.Linear(16*5*5, 120)   # convert matrix with 16*5*5 (= 400) features to a matrix of 120 features (columns)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)       # convert matrix with 120 features to a matrix of 84 features (columns)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)        # convert matrix with 84 features to a matrix of 10 features (columns)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # convolve, then perform ReLU non-linearity\n",
    "        x = torch.nn.functional.relu(self.conv1(x))  \n",
    "        # max-pooling with 2x2 grid\n",
    "        x = self.max_pool_1(x)\n",
    "        # convolve, then perform ReLU non-linearity\n",
    "        x = torch.nn.functional.relu(self.conv2(x))\n",
    "        # max-pooling with 2x2 grid\n",
    "        x = self.max_pool_2(x)\n",
    "        # first flatten 'max_pool_2_out' to contain 16*5*5 columns\n",
    "        # read through https://stackoverflow.com/a/42482819/7551231\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        # FC-1, then perform ReLU non-linearity\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        # FC-2, then perform ReLU non-linearity\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        # FC-3\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "with torch.jit.optimized_execution(3):\n",
    "#     module = torch.jit.trace(n.forward, example_forward_input)\n",
    "    scripted_module = torch.jit.script(LeNet5())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : __torch__.LeNet5,\n",
       "      %x.1 : Tensor):\n",
       "  %40 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %34 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %23 : int = prim::Constant[value=-1]() # <ipython-input-12-90096b50665d>:30:19\n",
       "  %15 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %6 : Function = prim::Constant[name=\"relu\"]()\n",
       "  %5 : bool = prim::Constant[value=0]()\n",
       "  %24 : int = prim::Constant[value=16]() # <ipython-input-12-90096b50665d>:30:23\n",
       "  %25 : int = prim::Constant[value=5]() # <ipython-input-12-90096b50665d>:30:26\n",
       "  %2 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%self)\n",
       "  %4 : Tensor = prim::CallMethod[name=\"forward\"](%2, %x.1) # <ipython-input-12-90096b50665d>:21:37\n",
       "  %x.3 : Tensor = prim::CallFunction(%6, %4, %5) # <ipython-input-12-90096b50665d>:21:12\n",
       "  %8 : __torch__.torch.nn.modules.pooling.MaxPool2d = prim::GetAttr[name=\"max_pool_1\"](%self)\n",
       "  %x.5 : Tensor = prim::CallMethod[name=\"forward\"](%8, %x.3) # <ipython-input-12-90096b50665d>:23:12\n",
       "  %11 : __torch__.torch.nn.modules.conv.___torch_mangle_6.Conv2d = prim::GetAttr[name=\"conv2\"](%self)\n",
       "  %13 : Tensor = prim::CallMethod[name=\"forward\"](%11, %x.5) # <ipython-input-12-90096b50665d>:25:37\n",
       "  %x.7 : Tensor = prim::CallFunction(%15, %13, %5) # <ipython-input-12-90096b50665d>:25:12\n",
       "  %17 : __torch__.torch.nn.modules.pooling.MaxPool2d = prim::GetAttr[name=\"max_pool_2\"](%self)\n",
       "  %x.9 : Tensor = prim::CallMethod[name=\"forward\"](%17, %x.7) # <ipython-input-12-90096b50665d>:27:12\n",
       "  %26 : int = aten::mul(%24, %25) # <ipython-input-12-90096b50665d>:30:23\n",
       "  %27 : int = aten::mul(%26, %25) # <ipython-input-12-90096b50665d>:30:23\n",
       "  %28 : int[] = prim::ListConstruct(%23, %27)\n",
       "  %x.11 : Tensor = aten::view(%x.9, %28) # <ipython-input-12-90096b50665d>:30:12\n",
       "  %30 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc1\"](%self)\n",
       "  %32 : Tensor = prim::CallMethod[name=\"forward\"](%30, %x.11) # <ipython-input-12-90096b50665d>:32:37\n",
       "  %x.13 : Tensor = prim::CallFunction(%34, %32, %5) # <ipython-input-12-90096b50665d>:32:12\n",
       "  %36 : __torch__.torch.nn.modules.linear.___torch_mangle_7.Linear = prim::GetAttr[name=\"fc2\"](%self)\n",
       "  %38 : Tensor = prim::CallMethod[name=\"forward\"](%36, %x.13) # <ipython-input-12-90096b50665d>:34:37\n",
       "  %x.15 : Tensor = prim::CallFunction(%40, %38, %5) # <ipython-input-12-90096b50665d>:34:12\n",
       "  %42 : __torch__.torch.nn.modules.linear.___torch_mangle_8.Linear = prim::GetAttr[name=\"fc3\"](%self)\n",
       "  %x.17 : Tensor = prim::CallMethod[name=\"forward\"](%42, %x.15) # <ipython-input-12-90096b50665d>:36:12\n",
       "  return (%x.17)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripted_module.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def forward(self,\\n    x: Tensor) -> Tensor:\\n  _0 = __torch__.torch.nn.functional.___torch_mangle_17.relu\\n  _1 = __torch__.torch.nn.functional.___torch_mangle_18.relu\\n  _2 = __torch__.torch.nn.functional.___torch_mangle_19.relu\\n  _3 = __torch__.torch.nn.functional.___torch_mangle_20.relu\\n  x0 = _0((self.conv1).forward(x, ), False, )\\n  x1 = (self.max_pool_1).forward(x0, )\\n  x2 = _1((self.conv2).forward(x1, ), False, )\\n  x3 = (self.max_pool_2).forward(x2, )\\n  x4 = torch.view(x3, [-1, torch.mul(torch.mul(16, 5), 5)])\\n  x5 = _2((self.fc1).forward(x4, ), False, )\\n  x6 = _3((self.fc2).forward(x5, ), False, )\\n  return (self.fc3).forward(x6, )\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripted_module.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 1, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "n = Net()\n",
    "example_weight = torch.rand(1, 1, 3, 3)\n",
    "example_forward_input = torch.rand(1, 1, 3, 3)\n",
    "\n",
    "# Trace a specific method and construct `ScriptModule` with\n",
    "# a single `forward` method\n",
    "with torch.jit.optimized_execution(3):\n",
    "    module = torch.jit.trace(n.forward, example_forward_input)\n",
    "\n",
    "# Trace a module (implicitly traces `forward`) and construct a\n",
    "# `ScriptModule` with a single `forward` method\n",
    "# module = torch.jit.trace(n, example_forward_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.torch.nn.modules.module.___torch_mangle_34.Module,\n",
       "      %input : Float(1, 1, 3, 3)):\n",
       "  %28 : __torch__.torch.nn.modules.module.___torch_mangle_33.Module = prim::GetAttr[name=\"conv\"](%self.1)\n",
       "  %30 : Tensor = prim::CallMethod[name=\"forward\"](%28, %input)\n",
       "  return (%30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.torch.nn.modules.module.___torch_mangle_38.Module,\n",
       "      %input : Float(1, 1, 3, 3)):\n",
       "  %28 : __torch__.torch.nn.modules.module.___torch_mangle_37.Module = prim::GetAttr[name=\"conv\"](%self.1)\n",
       "  %30 : Tensor = prim::CallMethod[name=\"forward\"](%28, %input)\n",
       "  return (%30)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
